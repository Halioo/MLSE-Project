{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compte-rendu - projet de génération d'un modèle de détection de mouvement de balancier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOC\n",
    "* [Partie 1](#1)\n",
    "* [Partie 2](#2)\n",
    "* [Partie 3](#3)\n",
    "* [Partie 4](#4)\n",
    "* [Partie 5](#5)\n",
    "* [Partie 6](#6)\n",
    "* [Partie 7](#7)\n",
    "* [Partie 8](#8)\n",
    "* [Partie 9](#9)\n",
    "* [Partie 10](#10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation <a class=\"anchor\" id=\"1\"></a>\n",
    "Import des packages utile\n",
    "\n",
    "* `pandas` : librairie pour manipuler les données (`DataFrame`)\n",
    "* `numpy` : librairie mathématique\n",
    "* `matplotlib` : librairie graphique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Récupération des données <a class=\"anchor\" id=\"2\"></a>\n",
    "\n",
    "Nous avons au préalable réalisé des enregistrements de données des capteurs (disponibles dans le dossier `/data`).\n",
    "Nous avons stocké dans un [Google sheet](https://docs.google.com/spreadsheets/d/1By59dQ56zL_kP0tW9Iyf4FppyEvJtcwnuG4gx1iokpM/edit?usp=sharing) si les captures correspondent à un état de balancier, ou non.\n",
    "Nous devons traiter cette donnée brute pour la rendre plus compréhensible et interprétable par Keras.\n",
    "\n",
    "La première étape est de trim les enregistrements pour ne garder que la partie qui nous intéresse.\n",
    "Cela est surtout important dans le cas où notre capture représente un mouvement de balancier, car la donnée brute inclut, au début et à la fin, des instants où l'objet ne se balance pas. Cela correspond au temps qu'il s'écoule entre l'activation de la capture et le début du mouvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limites des données utiles de chaque fichier .csv\n",
    "LIMITES = [ [60, 650],   [50, 350],  [100, 600],\n",
    "            [0, 550],    [0, 550],   [150, 250],\n",
    "            [0, 700],    [75, 820],  [0, 500],\n",
    "            [50, 550],   [50, 750],  [50, 900],\n",
    "            [0, 900],    [50, 1000], [100, 1200],\n",
    "            [50, 1300],  [50, 900],  [200, 700],\n",
    "            [0, 60],     [0, 60],    [0, 25],\n",
    "            [100, 800],  [100, 900], [100, 600],\n",
    "            [100, 850],  [50, 900],  [100, 1500],\n",
    "            [100, 2200], [30, 300],  [0, 650],\n",
    "            [0, 550],    [100, 500], [0, 710]]\n",
    "\n",
    "len(LIMITES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset =[]\n",
    "\n",
    "def trimDataset(ds):\n",
    "    for i in range(len(ds)):\n",
    "        ds[i] = ds[i][LIMITES[i][0]:LIMITES[i][1]]\n",
    "\n",
    "\n",
    "for i in range(len(LIMITES)):\n",
    "    dataset.append(pd.read_csv(\"data/balancier\" + str(i) + \".csv\"))\n",
    "    trimDataset(dataset)\n",
    "\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse des données\n",
    "On commence par importer les données depuis un fichier CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv('data/old/SensorTile_Log_N008.csv')\n",
    "d.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanDataframe(df):\n",
    "    df = df.drop(columns=[\"T [ms]\"])\n",
    "    return df\n",
    "\n",
    "def sliceDf(df, step):\n",
    "    res = []\n",
    "    while (len(df) > step):\n",
    "        res.append(df.iloc[:step])\n",
    "        df = df.iloc[step:]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d = cleanDataframe(d)\n",
    "d.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = sliceDf(d, 100)\n",
    "len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(d[\"AccX [mg]\"])\n",
    "plt.plot(d[\"AccY [mg]\"])\n",
    "plt.plot(d[\"AccZ [mg]\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(d[\"GyroX [mdps]\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch balancier data depuis Gsheet\n",
    "\n",
    "Récupération du résultat attendu depuis un Google Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gSheet import SheetAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ID and range of a sample spreadsheet.\n",
    "SPREADSHEET_ID = '1By59dQ56zL_kP0tW9Iyf4FppyEvJtcwnuG4gx1iokpM'\n",
    "api = SheetAPI(SPREADSHEET_ID)\n",
    "api.connect()\n",
    "print(api.getValues(\"A2:D100\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing the data\n",
    "\n",
    "Given the data, we can parse it to extract the information we need.\n",
    "\n",
    "First we slice the dataframe into multiple 1-sec **rolling** windows\n",
    "Then we multiply the data by sampling the data into subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 50 # Hz\n",
    "DATA_RATE = 20 # Hz\n",
    "WINDOW_LENGTH = 2000 # (in ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sliceDf(df, step):\n",
    "    res = []\n",
    "    while (len(df) > step):\n",
    "        res.append(df.iloc[:step])\n",
    "        df = df.iloc[1:]\n",
    "    return res\n",
    "\n",
    "def removeTime(df):\n",
    "    df = df.drop(columns=[\"T [ms]\"])\n",
    "    return df\n",
    "\n",
    "def sampleDf(df, sample):\n",
    "    res = []\n",
    "    for i in range(0, sample): # A tester\n",
    "        res.append(df.iloc[lambda x: x.index % sample == i])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv('data/balancier0.csv')\n",
    "d.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.tail(10)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e76f0dc653f8d2ef4c080a707dc31e02e03574b68b8024816724bcd14c82a0bd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
